{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__9OxgWOqUe5"
      },
      "outputs": [],
      "source": [
        "#tensorflow is the deep learning framework\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#keras is a wrapper class\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#Dropout regularization: to get rid of overfitting problems\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG-9UIYhr2dr"
      },
      "outputs": [],
      "source": [
        "#as in this dataset,we already know there are 10 classes, so we can define it\n",
        "#number of classes-do not change unless the data changes\n",
        "num_classes = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUrbVbgrtAY0"
      },
      "outputs": [],
      "source": [
        "#size of batch and no.of epochs of data\n",
        "batch_size = 64\n",
        "epochs = 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiNCmRPitOTl"
      },
      "outputs": [],
      "source": [
        "#defining the dimension of image as each and every img is of different dimension\n",
        "#so, we should normalize each and every image and that is why we are defining the dimension i.e. here 28*28\n",
        "#resizing all the images to 28 * 28 format\n",
        "img_rows, img_cols = 28,28\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CK5b4oLut5Sj"
      },
      "outputs": [],
      "source": [
        "#data,shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0UqTlNXux0g",
        "outputId": "c66bca08-758b-4eaf-eab9-40e10c0cf304"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK9AKETtvxbn"
      },
      "outputs": [],
      "source": [
        "#so, here we can see that the training data has 60,000 data and batch size = 64\n",
        "#so, the no.of iteration required in one epoch = 60,000/64 = 937.5 iterations\n",
        "#and so total no. of epochs = 24, so, 937.5 *24  = 22,500 times total iterations and 22,500 times weights will be updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXk3WBcwvUpb",
        "outputId": "c63b7746-108a-4fe6-c5fd-abe15ddc8617"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q82W7oKOvZJL",
        "outputId": "dcb06140-5b17-4375-f505-c1a29ce62221"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXGRue2kvcGT",
        "outputId": "623faa6b-03f7-4503-87bb-4e7056357f9c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fceeMQdnwrol",
        "outputId": "dcb43076-d3fa-4bde-f0af-70a8d9b8640b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fv-NeJ-1WrF"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) # we have passed at last 1 here for all as it is gray -scale img\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols,1)\n",
        "input_shape = (img_rows, img_cols,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQh4-WGR1ztL",
        "outputId": "736d4b04-20c1-4a73-eee2-55999a318f22"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwXmpyO81342",
        "outputId": "455ed9f7-b75f-40e4-f8a8-afe9214cae28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNbwPoXq17yq",
        "outputId": "e1666da2-6de9-488a-f3ed-c5f60bfbfb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "[9 0 0]\n"
          ]
        }
      ],
      "source": [
        "#type convert and scale the test and the training data\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "#doing feature scaling down\n",
        "x_train /= 255.\n",
        "x_test /= 255.\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print(y_train[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOqo1EfP4JUY",
        "outputId": "3b943e0c-0af1-4ec4-bb6f-a49c00f97be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "#convert class vectors to binary class matrices-- one hot encoding\n",
        "#one hot encoding converts numerical categorical variables into binary vectors\n",
        "# this type of encoding creates a new binary feature for each possible category and assigns a value of 1 to the\n",
        "#feature of each sample that corresponds to its original category.\n",
        "# 3 -> 0 0 0 1 0 0 0 0 0 0  and  1 => 0 1 0 0 0 0 0 0 0 0 \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_train[0:2]) #to verify one hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ABAggE6qIc"
      },
      "source": [
        "#cnn code \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJgJNkjg6PBZ"
      },
      "outputs": [],
      "source": [
        "#define the model\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv1HsM696aMm",
        "outputId": "eb4a15f2-e6da-47c1-e172-5b4a94fd9d95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQCU78jb6fL6"
      },
      "source": [
        "Create a CNN to classify images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6XsLwb-6h7i"
      },
      "outputs": [],
      "source": [
        "#below we are creating 2 layer Conv2D network\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape)) \n",
        "#here above 32 is the hyperparameter which definres the no. of filters and kernel_size is the filter size\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, kernel_size =(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu')) #fully-connected layers\n",
        "model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "#softmax function assigns decimal probabilities to each class in a multi-class problem\n",
        "\n",
        "   #output layer, here the no.of neurons will\n",
        "#be equal to num_classes as 10 categories = num_classes and that many neurons should only be \n",
        "#present as num_classes categories will be there\n",
        "\n",
        "#if it is the binary classification, then we can use sigmoid fn in the output/final dense output layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "0GhQwoW4OKxg",
        "outputId": "e606e06d-d0d7-48ba-98ce-95b45be30abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "938/938 [==============================] - 33s 35ms/step - loss: 0.0530 - accuracy: 0.9800 - val_loss: 0.4203 - val_accuracy: 0.9107\n",
            "Epoch 2/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0496 - accuracy: 0.9813 - val_loss: 0.4542 - val_accuracy: 0.9073\n",
            "Epoch 3/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0459 - accuracy: 0.9829 - val_loss: 0.4635 - val_accuracy: 0.9075\n",
            "Epoch 4/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 0.4680 - val_accuracy: 0.9073\n",
            "Epoch 5/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0427 - accuracy: 0.9838 - val_loss: 0.4751 - val_accuracy: 0.9106\n",
            "Epoch 6/24\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0362 - accuracy: 0.9866 - val_loss: 0.4689 - val_accuracy: 0.9069\n",
            "Epoch 7/24\n",
            "938/938 [==============================] - 29s 30ms/step - loss: 0.0400 - accuracy: 0.9844 - val_loss: 0.4805 - val_accuracy: 0.9098\n",
            "Epoch 8/24\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0353 - accuracy: 0.9868 - val_loss: 0.5289 - val_accuracy: 0.9071\n",
            "Epoch 9/24\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0374 - accuracy: 0.9862 - val_loss: 0.5246 - val_accuracy: 0.9108\n",
            "Epoch 10/24\n",
            "938/938 [==============================] - 28s 30ms/step - loss: 0.0315 - accuracy: 0.9885 - val_loss: 0.5499 - val_accuracy: 0.9111\n",
            "Epoch 11/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0331 - accuracy: 0.9879 - val_loss: 0.5630 - val_accuracy: 0.9103\n",
            "Epoch 12/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0304 - accuracy: 0.9891 - val_loss: 0.5649 - val_accuracy: 0.9083\n",
            "Epoch 13/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0320 - accuracy: 0.9882 - val_loss: 0.5753 - val_accuracy: 0.9065\n",
            "Epoch 14/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.5622 - val_accuracy: 0.9113\n",
            "Epoch 15/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0280 - accuracy: 0.9895 - val_loss: 0.6009 - val_accuracy: 0.9030\n",
            "Epoch 16/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0297 - accuracy: 0.9894 - val_loss: 0.6361 - val_accuracy: 0.9074\n",
            "Epoch 17/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0256 - accuracy: 0.9910 - val_loss: 0.6206 - val_accuracy: 0.9080\n",
            "Epoch 18/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0324 - accuracy: 0.9883 - val_loss: 0.6351 - val_accuracy: 0.9089\n",
            "Epoch 19/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.6797 - val_accuracy: 0.9079\n",
            "Epoch 20/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0285 - accuracy: 0.9897 - val_loss: 0.6635 - val_accuracy: 0.9088\n",
            "Epoch 21/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.6510 - val_accuracy: 0.9028\n",
            "Epoch 22/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0317 - accuracy: 0.9893 - val_loss: 0.6192 - val_accuracy: 0.9117\n",
            "Epoch 23/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.6488 - val_accuracy: 0.9106\n",
            "Epoch 24/24\n",
            "938/938 [==============================] - 29s 31ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.7061 - val_accuracy: 0.9018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nverbose basically means logs. It accepts values as 0/1. If you put Verbose value as 1 in ModelCheckPoint callback, after\\n each epoch you will get the statement after each epoch that the model got improved from error 456 to 123\\n or model did not improve in this epoch \\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "#define compile to minimize the categorical loss, use some optimizer to optimize,ada delta optimized, and optimize to maximum accuracy\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])\n",
        "\n",
        "#categorical cross entropy/ sparse categorical cross-entropy is the loss function for multi-class classification and it is binary cross entropy for binary classification\n",
        "#there are other better optimizers than Adam (Adaptive Moment Estimation) Optimizer like SDD optimizer, RMSprop optimizer, and we can use these\n",
        "#Adam is a replacement optimization algorithm for stochastic gradientdescent for training deep learning models.\n",
        "\n",
        "\n",
        "#train the model and test/validate the mode with the test data after each cycle(epoch) through the training data\n",
        "#return the history of loss and accuracy for each epoch\n",
        "hist = model.fit(x_train, y_train, batch_size= batch_size, \n",
        "                 epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "#here batch size = 64 and epochs = 24\n",
        "\n",
        "\"\"\"\n",
        "verbose basically means logs. It accepts values as 0/1. If you put Verbose value as 1 in ModelCheckPoint callback, after\n",
        " each epoch you will get the statement after each epoch that the model got improved from error 456 to 123\n",
        " or model did not improve in this epoch \n",
        " \"\"\"\n",
        " \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKyfT-4OgVIM",
        "outputId": "273dbae3-e269-49bc-909f-3b5b5f73074f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.053029656410217285,\n",
              "  0.04960523918271065,\n",
              "  0.04587823152542114,\n",
              "  0.04553401842713356,\n",
              "  0.04270991310477257,\n",
              "  0.036239977926015854,\n",
              "  0.040004145354032516,\n",
              "  0.03531184792518616,\n",
              "  0.037380021065473557,\n",
              "  0.03153898939490318,\n",
              "  0.03309536725282669,\n",
              "  0.030354583635926247,\n",
              "  0.03200914338231087,\n",
              "  0.02917293831706047,\n",
              "  0.028012998402118683,\n",
              "  0.029653184115886688,\n",
              "  0.025627031922340393,\n",
              "  0.03242238610982895,\n",
              "  0.02074713259935379,\n",
              "  0.028455369174480438,\n",
              "  0.02330111153423786,\n",
              "  0.03173986077308655,\n",
              "  0.022451601922512054,\n",
              "  0.019894540309906006],\n",
              " 'accuracy': [0.9799666404724121,\n",
              "  0.9812999963760376,\n",
              "  0.9828500151634216,\n",
              "  0.9831833243370056,\n",
              "  0.9837833046913147,\n",
              "  0.9865833520889282,\n",
              "  0.9843833446502686,\n",
              "  0.9868000149726868,\n",
              "  0.9861833453178406,\n",
              "  0.9884833097457886,\n",
              "  0.9879000186920166,\n",
              "  0.9890666604042053,\n",
              "  0.988183319568634,\n",
              "  0.9895166754722595,\n",
              "  0.989466667175293,\n",
              "  0.9894166588783264,\n",
              "  0.991016685962677,\n",
              "  0.9883333444595337,\n",
              "  0.9926999807357788,\n",
              "  0.9896666407585144,\n",
              "  0.9920499920845032,\n",
              "  0.989300012588501,\n",
              "  0.9922500252723694,\n",
              "  0.9932666420936584],\n",
              " 'val_loss': [0.4202991724014282,\n",
              "  0.45418065786361694,\n",
              "  0.4634857773780823,\n",
              "  0.46804100275039673,\n",
              "  0.475138783454895,\n",
              "  0.46887820959091187,\n",
              "  0.48050811886787415,\n",
              "  0.528892993927002,\n",
              "  0.5245689749717712,\n",
              "  0.5499330163002014,\n",
              "  0.5629870891571045,\n",
              "  0.5649489760398865,\n",
              "  0.5753008723258972,\n",
              "  0.562204122543335,\n",
              "  0.6009230613708496,\n",
              "  0.6360963582992554,\n",
              "  0.6205950379371643,\n",
              "  0.6350971460342407,\n",
              "  0.6797261238098145,\n",
              "  0.6634501218795776,\n",
              "  0.651013195514679,\n",
              "  0.6191650629043579,\n",
              "  0.6487964987754822,\n",
              "  0.7060850858688354],\n",
              " 'val_accuracy': [0.9107000231742859,\n",
              "  0.9072999954223633,\n",
              "  0.9075000286102295,\n",
              "  0.9072999954223633,\n",
              "  0.9106000065803528,\n",
              "  0.9068999886512756,\n",
              "  0.9097999930381775,\n",
              "  0.9071000218391418,\n",
              "  0.9107999801635742,\n",
              "  0.9110999703407288,\n",
              "  0.9103000164031982,\n",
              "  0.90829998254776,\n",
              "  0.906499981880188,\n",
              "  0.911300003528595,\n",
              "  0.902999997138977,\n",
              "  0.9074000120162964,\n",
              "  0.9079999923706055,\n",
              "  0.9089000225067139,\n",
              "  0.9078999757766724,\n",
              "  0.9088000059127808,\n",
              "  0.9028000235557556,\n",
              "  0.9117000102996826,\n",
              "  0.9106000065803528,\n",
              "  0.9017999768257141]}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model with the test data to get the scores on 'real' data.\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "#plot data to see relationships in training and validation data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "# it sets the backend of matplotlib to the 'inline' backend\n",
        "epoch_list = list(range(1, len(hist.history['accuracy']) + 1)) #values of x-axis-[1,2,3....]\n",
        "plt.plot(epoch_list, hist.history['accuracy'], epoch_list, hist.history['val_accuracy'])\n",
        "plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "2CkS0h2-j11w",
        "outputId": "36fda9a2-f024-44ee-abc4-7398e5a0e00c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.7060851454734802\n",
            "Test accuracy: 0.9017999768257141\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPhw65Bui4RC",
        "outputId": "f9e098cb-3082-4ec5-817f-a4b636bfefdb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 800)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               102528    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121,002\n",
            "Trainable params: 121,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#observations\n",
        "#in Conv2D, before the i/p image was 28 * 28 *1, and after  that as visible it is 26*26*32 , so\n",
        "#filter size is 32, and whenever there are n*n filter and when stride=1, so, we get (n-2)*(n-2) matrix.\n",
        "\n",
        "#maxpooling of 2*2 is cutting down the pixels by 2 i.e. /2 ; so here 26/2 = 13*13\n",
        "\n",
        "#then n-2, = 13-2 =11 (conv2d)\n",
        "#and then 13/2 = 5 (maxpooling 2d)\n",
        "# for flattening, multiply the pixels; -> 5*5*32 = 800\n",
        "\n"
      ],
      "metadata": {
        "id": "aVb-O4iwjGGW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parameters in a Conv Layer:(Param)\n",
        "((shape of width of filter * shape of height of filter * number of filters in the previous layer+1)* no. of filters)\n",
        "\n",
        "so, for first one:  width of filter = 3, height of filter = 3, no. of filters in prev layer = 1, no. of filters =32\n",
        "so, ((3*3*1+1)*32) = 10*32 = 320\n",
        "\n",
        "for 2nd conv2d layer: width =3, height=3, no.of filters in prev layer=32, no. of filters = 32\n",
        "so,((3*3*32+1)*32) = (288+1)*32 = 9248\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "FdwrgPGNaTl0",
        "outputId": "591a1ac9-253b-4333-c05c-6d5429d0b4f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nParameters in a Conv Layer:(Param)\\n((shape of width of filter * shape of height of filter * number of filters in the previous layer+1)* no. of filters)\\n\\nso, for first one:  width of filter = 3, height of filter = 3, no. of filters in prev layer = 1, no. of filters =32\\nso, ((3*3*1+1)*32) = 10*32 = 320\\n\\nfor 2nd conv2d layer: width =3, height=3, no.of filters in prev layer=32, no. of filters = 32\\nso,((3*3*32+1)*32) = (288+1)*32 = 9248\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parameters in FC(Fully Connected) layer :\n",
        "((current layer c * previous layer p)+1 *c)\n",
        "\n",
        "for 1st dense layer: current layer=128, prev layer=800\n",
        "so, ((128*800)+1 *128) = 102528\n",
        "for 2nd dense layer:\n",
        "  c= 64, p=128,\n",
        "  so, ((64*128)+1 * 64) = 8256\n",
        "\n",
        "  for 3rd dense layer/output layer:\n",
        "    c=10, p=64\n",
        "    so,((10*64)+10) = 650\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "_xktN-vIinBZ",
        "outputId": "6d029ac6-c4cf-485f-dba4-dff9318568d7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nParameters in FC(Fully Connected) layer :\\n((current layer c * previous layer p)+1 *c)\\n\\nfor 1st dense layer: current layer=128, prev layer=800\\nso, ((128*800)+1 *128) = 102528\\nfor 2nd dense layer:\\n  c= 64, p=128,\\n  so, ((64*128)+1 * 64) = 8256\\n\\n  for 3rd dense layer/output layer:\\n    c=10, p=64\\n    so,((10*64)+10) = 650\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}